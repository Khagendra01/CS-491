{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow import keras\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_src_path = '../../Dataset/mixed_text_assignment.json'\n",
    "y_src_path = '../../DataBook/Mixed_Data_Analyst.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(x_src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervision = pd.read_excel(y_src_path)\n",
    "plagiarised_array = df_supervision['Plagiarised'].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data.iloc[:, :].astype(str).values.tolist()\n",
    "\n",
    "texts = [[element if element != 'None' else '' for element in sublist] for sublist in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\") \n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "max_sequence_len = max([len(seq) for seq in sequences])\n",
    "data_vectorized = pad_sequences(sequences, maxlen=max_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_vectorized\n",
    "y = plagiarised_array\n",
    "ros = SMOTE()\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=14)\n",
    "#seed 32 results 100% on test score 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 34\n",
      "Number of 1s: 6\n"
     ]
    }
   ],
   "source": [
    "count_0 = 0\n",
    "count_1 = 0\n",
    "\n",
    "for element in y_test:\n",
    "    if element == 0:\n",
    "        count_0 += 1\n",
    "    elif element == 1:\n",
    "        count_1 += 1\n",
    "\n",
    "print(\"Number of 0s:\", count_0)\n",
    "print(\"Number of 1s:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 1.0\n",
      "Test data score: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "p = Perceptron()\n",
    "p.fit(X_train,y_train)\n",
    "\n",
    "print(f\"Training data score: {p.score(X_train, y_train)}\")\n",
    "print(f\"Test data score: {p.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = p.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 1.0\n",
      "Test data score: 0.85\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training data score: {train_accuracy}\")\n",
    "print(f\"Test data score: {test_accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3/3 [==============================] - 1s 83ms/step - loss: 26.4643 - accuracy: 0.7527 - val_loss: 15.4677 - val_accuracy: 0.8500\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 7.0194 - accuracy: 0.8710 - val_loss: 5.0261 - val_accuracy: 0.8250\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.5660 - accuracy: 0.8387 - val_loss: 6.4945 - val_accuracy: 0.7000\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 6.9002 - val_accuracy: 0.8750\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2035 - accuracy: 0.9892 - val_loss: 7.8756 - val_accuracy: 0.9000\n",
      "model eval\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.8756 - accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.8756103515625, 0.8999999761581421]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(10315,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "LOSS_FN = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(optimizer='adam', loss=LOSS_FN, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
    "print(\"model eval\")\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 1, Perceptron: 1 Actual: 1\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 1 Actual: 1\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 1\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 1\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 1\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 1, Perceptron: 1 Actual: 1\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "y_pred_text = model.predict(X_test)\n",
    "y_pred_text_binary = np.where(y_pred_text >= threshold, 1, 0)\n",
    "y_pred_text_binary_flat = y_pred_text_binary.flatten()\n",
    "\n",
    "for pred, actual, percep in zip(y_pred_text_binary_flat, predictions, y_test):\n",
    "    print(f\"Neural: {pred}, Perceptron: {percep} Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNames = [\n",
    "    '1d',\n",
    "    '2d',\n",
    "    '3d',\n",
    "    '4d',\n",
    "    '5d',\n",
    "    '6d',\n",
    "    '7d'\n",
    "]\n",
    "\n",
    "NODES_PER_HIDDEN_LAYER = 32\n",
    "\n",
    "models = [ \n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(10315,)),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "]),\n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(10315,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(10315,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(10315,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(10315,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(10315,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(10315,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_FN = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "for model in models:\n",
    "    model.compile(optimizer='adam',loss=LOSS_FN,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model perceptron\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 8.7173e-09 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 8.3604e-09 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 8.1952e-09 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.9787e-09 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.8983e-09 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.7947e-09 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.6682e-09 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 7.6458e-09 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.5912e-09 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.5586e-09 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.5359e-09 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.5198e-09 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.5091e-09 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.4947e-09 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.4897e-09 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.4845e-09 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.4776e-09 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.4751e-09 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.4729e-09 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.4698e-09 - accuracy: 1.0000\n",
      "training model 1d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.8415e-12 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.3880e-12 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.1605e-12 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.7693e-12 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 7.6168e-12 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.5387e-12 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.4237e-12 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.4015e-12 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.3323e-12 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.2959e-12 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 7.2691e-12 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.2438e-12 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.2389e-12 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.2209e-12 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.2181e-12 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 7.2097e-12 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.2042e-12 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.2021e-12 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.2004e-12 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 7.1979e-12 - accuracy: 1.0000\n",
      "training model 2d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6657e-06 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.6796e-06 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6821e-06 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6741e-06 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6500e-06 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.6214e-06 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.5762e-06 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5510e-06 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5025e-06 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4674e-06 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4349e-06 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3992e-06 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3655e-06 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3200e-06 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2913e-06 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2483e-06 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2285e-06 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1863e-06 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1623e-06 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1232e-06 - accuracy: 1.0000\n",
      "training model 3d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.3422e-06 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7753e-06 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6836e-06 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2914e-06 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.6237e-07 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.9368e-07 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.6235e-07 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 5.3937e-07 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.5956e-07 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3867e-07 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2168e-07 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.9189e-07 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.7977e-07 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.7030e-07 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.6498e-07 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5820e-07 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.5261e-07 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.4663e-07 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.4398e-07 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.4028e-07 - accuracy: 1.0000\n",
      "training model 4d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7369e-04 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6235e-04 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5550e-04 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5038e-04 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4402e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3940e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3487e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3057e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2644e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2333e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1908e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1572e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1202e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0994e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0683e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0426e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0133e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.9244e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.7324e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.5267e-05 - accuracy: 1.0000\n",
      "training model 5d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1515e-04 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0014e-04 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8396e-04 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7490e-04 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.6515e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5901e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5133e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4411e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3583e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3217e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2611e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2161e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1844e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1553e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1236e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0921e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0706e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0369e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0125e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 9.9665e-05 - accuracy: 1.0000\n",
      "training model 6d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4281e-04 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3431e-04 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2641e-04 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2095e-04 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1456e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0997e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0614e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0246e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.8588e-05 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.5068e-05 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 9.2489e-05 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.9563e-05 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 8.6281e-05 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.4055e-05 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.1732e-05 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 7.9262e-05 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.7058e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 7.5460e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.3413e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 7.1420e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "TRAINING_EPOCHS = 20\n",
    "\n",
    "# train all models\n",
    "for model, name in zip(models, modelNames):\n",
    "    print(f'training model {name}')\n",
    "    model.fit(X_train, y_train, epochs=TRAINING_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6171 - accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.4619 - accuracy: 0.8750\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3439 - accuracy: 0.9000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1124 - accuracy: 0.9000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7624 - accuracy: 0.9000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.0151 - accuracy: 0.9250\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7138 - accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "# get all model accuracy scores on test data\n",
    "scores = [model.evaluate(X_test,y_test)[1] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "modelNames.insert(0, 'perceptron')\n",
    "scores.insert(0, p.score(X_test, y_test) )\n",
    "\n",
    "plt.bar(modelNames,scores)\n",
    "plt.ylim(0.75, 1.0)\n",
    "plt.ylabel('Test Accuracy (%)') \n",
    "plt.xlabel(str(NODES_PER_HIDDEN_LAYER) + \" nodes per hidden layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E8CA72A8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E8B70EB1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Model 1 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 2 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 3 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 4 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 5 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 6 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 7 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "probabilities = [model.predict(X_test) for model in models]\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_labels = [np.argmax(prob, axis=1) for prob in probabilities]\n",
    "\n",
    "# Assuming y_test is your actual labels\n",
    "# Convert y_test to class labels if it's not already in that format\n",
    "# This step depends on how y_test is structured. If it's one-hot encoded, you might need to use np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print predicted and actual labels for each model\n",
    "for i, labels in enumerate(predicted_labels):\n",
    "    print(f\"Model {i+1} Predicted Labels: {labels}\")\n",
    "    print(f\"Actual Labels: {y_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
