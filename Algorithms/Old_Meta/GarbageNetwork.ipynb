{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow import keras\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_src_path = '../../Dataset/MixedDataSet.json'\n",
    "y_src_path = '../../DataBook/Mixed_Data_Analyst.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(x_src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervision = pd.read_excel(y_src_path)\n",
    "plagiarised_array = df_supervision['Plagiarised'].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.nan_to_num(data.values, nan=0, copy=True).astype(int)\n",
    "y = plagiarised_array\n",
    "ros = SMOTE()\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
    "#seed 32 results 100% on test score 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 22\n",
      "Number of 1s: 5\n"
     ]
    }
   ],
   "source": [
    "count_0 = 0\n",
    "count_1 = 0\n",
    "\n",
    "for element in y_test:\n",
    "    if element == 0:\n",
    "        count_0 += 1\n",
    "    elif element == 1:\n",
    "        count_1 += 1\n",
    "\n",
    "print(\"Number of 0s:\", count_0)\n",
    "print(\"Number of 1s:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "#     print(\"this stage is \" + str(i))\n",
    "#     count_y_train_1 = np.sum(y_train == 1)\n",
    "#     count_y_test_1 = np.sum(y_test == 1)\n",
    "#     print(count_y_train_1)\n",
    "#     print(count_y_test_1)\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 0.989247311827957\n",
      "Test data score: 0.775\n"
     ]
    }
   ],
   "source": [
    "p = Perceptron()\n",
    "p.fit(X_train,y_train)\n",
    "\n",
    "print(f\"Training data score: {p.score(X_train, y_train)}\")\n",
    "print(f\"Test data score: {p.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86        33\n",
      "           1       0.40      0.57      0.47         7\n",
      "\n",
      "    accuracy                           0.78        40\n",
      "   macro avg       0.65      0.69      0.66        40\n",
      "weighted avg       0.81      0.78      0.79        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions = p.predict(X_test)\n",
    "# for i in range(len(X_test)):\n",
    "#     print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = p.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 1.0\n",
      "Test data score: 0.85\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training data score: {train_accuracy}\")\n",
    "print(f\"Test data score: {test_accuracy}\")\n",
    "\n",
    "xpredictions = model.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", xpredictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3/3 [==============================] - 1s 97ms/step - loss: 3016.4895 - accuracy: 0.7312 - val_loss: 3934.4551 - val_accuracy: 0.9000\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4369.0391 - accuracy: 0.8172 - val_loss: 3916.4348 - val_accuracy: 0.8000\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 2961.3118 - accuracy: 0.8065 - val_loss: 2783.8184 - val_accuracy: 0.7750\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1446.8041 - accuracy: 0.8280 - val_loss: 2225.8755 - val_accuracy: 0.9000\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 916.2703 - accuracy: 0.8925 - val_loss: 1992.4652 - val_accuracy: 0.7750\n",
      "model eval\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1992.4652 - accuracy: 0.7750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1992.4652099609375, 0.7749999761581421]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "LOSS_FN = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(optimizer='adam', loss=LOSS_FN, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
    "print(\"model eval\")\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 1, Perceptron: 1 Actual: 1\n",
      "Neural: 1, Perceptron: 1 Actual: 1\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 1, Perceptron: 0 Actual: 1\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "y_pred_train_binary = np.where(y_pred_train >= threshold, 1, 0)\n",
    "y_pred_test_binary = np.where(y_pred_test >= threshold, 1, 0)\n",
    "\n",
    "y_pred_test_binary_flat = y_pred_test_binary.flatten()\n",
    "for pred, actual, percep in zip(y_pred_test_binary_flat, xpredictions, y_test):\n",
    "    print(f\"Neural: {pred}, Perceptron: {percep} Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNames = [\n",
    "    '1d',\n",
    "    '2d',\n",
    "    '3d',\n",
    "    '4d',\n",
    "    '5d',\n",
    "    '6d',\n",
    "    '7d'\n",
    "]\n",
    "\n",
    "NODES_PER_HIDDEN_LAYER = 128\n",
    "\n",
    "models = [ \n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_FN = keras.losses.sparse_categorical_crossentropy\n",
    "\n",
    "for model in models:\n",
    "    model.compile(optimizer='adam',loss=LOSS_FN,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model 1d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3378.5823 - accuracy: 0.7204\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 15919.9893 - accuracy: 0.8495\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 12090.1562 - accuracy: 0.8602\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7715.9248 - accuracy: 0.7957\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6813.1035 - accuracy: 0.7742\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5596.1440 - accuracy: 0.8387\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3839.2769 - accuracy: 0.9032\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2342.9780 - accuracy: 0.9032\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 830.6109 - accuracy: 0.9140\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1118.0916 - accuracy: 0.8710\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 625.3225 - accuracy: 0.8925\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2176.1738 - accuracy: 0.9140\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1005.8699 - accuracy: 0.8387\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 229.0843 - accuracy: 0.9032\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 907.9080 - accuracy: 0.9355\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 609.3434 - accuracy: 0.9355\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 496.6537 - accuracy: 0.9462\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 297.8756 - accuracy: 0.9570\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 317.4042 - accuracy: 0.9247\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 130.2254 - accuracy: 0.9140\n",
      "training model 2d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 56ms/step - loss: 28841.2012 - accuracy: 0.6022\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 23864.9355 - accuracy: 0.8280\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 11906.4111 - accuracy: 0.8495\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 6629.9941 - accuracy: 0.8280\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2277.6184 - accuracy: 0.8065\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1781.1049 - accuracy: 0.7527\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1008.8065 - accuracy: 0.8710\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 587.2881 - accuracy: 0.9247\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 893.9148 - accuracy: 0.8925\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 885.8051 - accuracy: 0.9140\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 799.9277 - accuracy: 0.9247\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 360.2361 - accuracy: 0.9032\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 458.2434 - accuracy: 0.8280\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 221.8615 - accuracy: 0.9140\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 211.6950 - accuracy: 0.9140\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 381.8535 - accuracy: 0.9032\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 362.4849 - accuracy: 0.9140\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 139.4106 - accuracy: 0.9462\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 36.5786 - accuracy: 0.9355\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 123.7071 - accuracy: 0.9140\n",
      "training model 3d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 60ms/step - loss: 5730.0317 - accuracy: 0.6344\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3836.5867 - accuracy: 0.8172\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1943.5200 - accuracy: 0.6989\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1232.4663 - accuracy: 0.8710\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1355.1001 - accuracy: 0.8280\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 372.2154 - accuracy: 0.8925\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3397.3293 - accuracy: 0.9247\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3113.5723 - accuracy: 0.9140\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 637.1477 - accuracy: 0.9247\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 664.4381 - accuracy: 0.9032\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 235.4459 - accuracy: 0.9355\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 157.6284 - accuracy: 0.9570\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 303.9677 - accuracy: 0.8817\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 339.4705 - accuracy: 0.9570\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 805.7183 - accuracy: 0.9570\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 693.5955 - accuracy: 0.8495\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 634.0948 - accuracy: 0.9140\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 569.2740 - accuracy: 0.9355\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1688.1017 - accuracy: 0.8817\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 248.7773 - accuracy: 0.9140\n",
      "training model 4d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 61ms/step - loss: 5732.5752 - accuracy: 0.6344\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1745.0343 - accuracy: 0.7634\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2321.7883 - accuracy: 0.8495\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3224.0652 - accuracy: 0.8925\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3652.9849 - accuracy: 0.6989\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2946.7292 - accuracy: 0.9032\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1929.7568 - accuracy: 0.8817\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2643.6831 - accuracy: 0.8602\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2305.5051 - accuracy: 0.8172\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1344.9742 - accuracy: 0.9140\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 749.0435 - accuracy: 0.9032\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 505.8789 - accuracy: 0.9140\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 555.3602 - accuracy: 0.8710\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 836.7974 - accuracy: 0.8817\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 433.4103 - accuracy: 0.9355\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 167.5913 - accuracy: 0.9140\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 223.7734 - accuracy: 0.9355\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 118.2048 - accuracy: 0.9677\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 20.8577 - accuracy: 0.9677\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 92.3077 - accuracy: 0.9677\n",
      "training model 5d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 57ms/step - loss: 7720.8613 - accuracy: 0.4839\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2652.3682 - accuracy: 0.8495\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2542.6829 - accuracy: 0.8495\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2407.6194 - accuracy: 0.8602\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1710.6014 - accuracy: 0.8925\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1383.1637 - accuracy: 0.7634\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1533.6979 - accuracy: 0.8817\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 966.5150 - accuracy: 0.8602\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 758.1356 - accuracy: 0.7957\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 297.8513 - accuracy: 0.9140\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 259.9475 - accuracy: 0.8925\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 263.9811 - accuracy: 0.9032\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 809.7263 - accuracy: 0.9247\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 308.0919 - accuracy: 0.8065\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 516.3566 - accuracy: 0.9032\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 875.0842 - accuracy: 0.9247\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 286.5133 - accuracy: 0.9570\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 641.5873 - accuracy: 0.9032\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 883.7761 - accuracy: 0.9140\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 282.9596 - accuracy: 0.8710\n",
      "training model 6d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 59ms/step - loss: 4603.8706 - accuracy: 0.6129\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2638.4492 - accuracy: 0.6882\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3251.8462 - accuracy: 0.8495\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2509.6594 - accuracy: 0.7312\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 732.9891 - accuracy: 0.7742\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1412.8590 - accuracy: 0.8065\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1896.4034 - accuracy: 0.8495\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1028.0387 - accuracy: 0.7957\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1339.2070 - accuracy: 0.8817\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 865.4748 - accuracy: 0.7742\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 464.5382 - accuracy: 0.8495\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 305.3724 - accuracy: 0.8925\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 153.9987 - accuracy: 0.8817\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 158.9252 - accuracy: 0.8387\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 85.0462 - accuracy: 0.8602\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 77.4953 - accuracy: 0.9140\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 101.8531 - accuracy: 0.9032\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 54.1982 - accuracy: 0.8710\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 69.8822 - accuracy: 0.9247\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 31.8722 - accuracy: 0.9677\n",
      "training model 7d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 56ms/step - loss: 1482.8365 - accuracy: 0.5806\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1503.3077 - accuracy: 0.6989\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1534.4130 - accuracy: 0.7419\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1239.8752 - accuracy: 0.8495\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 872.5444 - accuracy: 0.7634\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 669.3335 - accuracy: 0.8710\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 853.7817 - accuracy: 0.7204\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 566.1255 - accuracy: 0.8817\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 285.2670 - accuracy: 0.8280\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 260.9015 - accuracy: 0.8710\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 108.4726 - accuracy: 0.8710\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 268.8530 - accuracy: 0.9032\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 202.1782 - accuracy: 0.7634\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 767.4615 - accuracy: 0.8817\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 167.2434 - accuracy: 0.9247\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1105.0505 - accuracy: 0.7527\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1451.8635 - accuracy: 0.8710\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 693.5681 - accuracy: 0.8710\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 613.1790 - accuracy: 0.6882\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 417.0257 - accuracy: 0.9247\n"
     ]
    }
   ],
   "source": [
    "TRAINING_EPOCHS = 20\n",
    "\n",
    "# train all models\n",
    "for model, name in zip(models, modelNames):\n",
    "    print(f'training model {name}')\n",
    "    model.fit(X_train, y_train, epochs=TRAINING_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 10635.3809 - accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4394.5938 - accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5925.7915 - accuracy: 0.8250\n",
      "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF90D245E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 832.0493 - accuracy: 0.8000\n",
      "WARNING:tensorflow:6 out of the last 21 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BF90D24B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2074.1125 - accuracy: 0.8750\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4694.4668 - accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1217.4727 - accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "# get all model accuracy scores on test data\n",
    "scores = [model.evaluate(X_test,y_test)[1] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelNames.insert(0, 'perceptron')\n",
    "scores.insert(0, p.score(X_test, y_test) )\n",
    "\n",
    "plt.bar(modelNames,scores)\n",
    "plt.ylim(0.75, 1.0)\n",
    "plt.ylabel('Test Accuracy (%)') \n",
    "plt.xlabel(str(NODES_PER_HIDDEN_LAYER) + \" nodes per hidden layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BF92116940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BF91FF3DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Model 1 Predicted Labels: [0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0]\n",
      "Model 2 Predicted Labels: [0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0]\n",
      "Model 3 Predicted Labels: [0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0]\n",
      "Model 4 Predicted Labels: [0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0]\n",
      "Model 5 Predicted Labels: [0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0]\n",
      "Model 6 Predicted Labels: [0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0]\n",
      "Model 7 Predicted Labels: [0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "probabilities = [model.predict(X_test) for model in models]\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_labels = [np.argmax(prob, axis=1) for prob in probabilities]\n",
    "\n",
    "# Assuming y_test is your actual labels\n",
    "# Convert y_test to class labels if it's not already in that format\n",
    "# This step depends on how y_test is structured. If it's one-hot encoded, you might need to use np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print predicted and actual labels for each model\n",
    "for i, labels in enumerate(predicted_labels):\n",
    "    print(f\"Model {i+1} Predicted Labels: {labels}\")\n",
    "    print(f\"Actual Labels: {y_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
