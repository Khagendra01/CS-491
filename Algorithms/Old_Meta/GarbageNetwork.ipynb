{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow import keras\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_src_path = '../Dataset/MixedDataSet.json'\n",
    "y_src_path = '../DataBook/Mixed_Data_Analyst.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(x_src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervision = pd.read_excel(y_src_path)\n",
    "plagiarised_array = df_supervision['Plagiarised'].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.nan_to_num(data.values, nan=0, copy=True).astype(int)\n",
    "y = plagiarised_array\n",
    "ros = SMOTE()\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=14)\n",
    "#seed 32 results 100% on test score 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 34\n",
      "Number of 1s: 6\n"
     ]
    }
   ],
   "source": [
    "count_0 = 0\n",
    "count_1 = 0\n",
    "\n",
    "for element in y_test:\n",
    "    if element == 0:\n",
    "        count_0 += 1\n",
    "    elif element == 1:\n",
    "        count_1 += 1\n",
    "\n",
    "print(\"Number of 0s:\", count_0)\n",
    "print(\"Number of 1s:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "#     print(\"this stage is \" + str(i))\n",
    "#     count_y_train_1 = np.sum(y_train == 1)\n",
    "#     count_y_test_1 = np.sum(y_test == 1)\n",
    "#     print(count_y_train_1)\n",
    "#     print(count_y_test_1)\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 1.0\n",
      "Test data score: 0.7\n"
     ]
    }
   ],
   "source": [
    "p = Perceptron()\n",
    "p.fit(X_train,y_train)\n",
    "\n",
    "print(f\"Training data score: {p.score(X_train, y_train)}\")\n",
    "print(f\"Test data score: {p.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82        34\n",
      "           1       0.12      0.17      0.14         6\n",
      "\n",
      "    accuracy                           0.70        40\n",
      "   macro avg       0.48      0.48      0.48        40\n",
      "weighted avg       0.74      0.70      0.72        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions = p.predict(X_test)\n",
    "# for i in range(len(X_test)):\n",
    "#     print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = p.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 1.0\n",
      "Test data score: 0.925\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training data score: {train_accuracy}\")\n",
    "print(f\"Test data score: {test_accuracy}\")\n",
    "\n",
    "xpredictions = model.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", xpredictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3/3 [==============================] - 1s 102ms/step - loss: 17940.9121 - accuracy: 0.5806 - val_loss: 2142.0439 - val_accuracy: 0.9000\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 5385.0835 - accuracy: 0.8817 - val_loss: 2362.6658 - val_accuracy: 0.9000\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4174.1685 - accuracy: 0.8817 - val_loss: 1504.7400 - val_accuracy: 0.8750\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 2310.7590 - accuracy: 0.8817 - val_loss: 995.5706 - val_accuracy: 0.8750\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1162.5271 - accuracy: 0.8602 - val_loss: 642.6302 - val_accuracy: 0.7750\n",
      "model eval\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 642.6302 - accuracy: 0.7750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[642.6301879882812, 0.7749999761581421]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "LOSS_FN = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(optimizer='adam', loss=LOSS_FN, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
    "print(\"model eval\")\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 1, Perceptron: 1 Actual: 1\n",
      "Neural: 1, Perceptron: 1 Actual: 1\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 1, Perceptron: 1 Actual: 1\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "y_pred_train_binary = np.where(y_pred_train >= threshold, 1, 0)\n",
    "y_pred_test_binary = np.where(y_pred_test >= threshold, 1, 0)\n",
    "\n",
    "y_pred_test_binary_flat = y_pred_test_binary.flatten()\n",
    "for pred, actual, percep in zip(y_pred_test_binary_flat, xpredictions, y_test):\n",
    "    print(f\"Neural: {pred}, Perceptron: {percep} Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNames = [\n",
    "    '1d',\n",
    "    '2d',\n",
    "    '3d',\n",
    "    '4d',\n",
    "    '5d',\n",
    "    '6d',\n",
    "    '7d'\n",
    "]\n",
    "\n",
    "NODES_PER_HIDDEN_LAYER = 128\n",
    "\n",
    "models = [ \n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_FN = keras.losses.sparse_categorical_crossentropy\n",
    "\n",
    "for model in models:\n",
    "    model.compile(optimizer='adam',loss=LOSS_FN,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model 1d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 19609.4180 - accuracy: 0.6237\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 10286.6436 - accuracy: 0.8817\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 13129.5918 - accuracy: 0.9032\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 11964.3857 - accuracy: 0.8602\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 10772.4443 - accuracy: 0.7527\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7391.0815 - accuracy: 0.7527\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2806.9539 - accuracy: 0.8925\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1635.3367 - accuracy: 0.9032\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2324.1685 - accuracy: 0.8925\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1228.1924 - accuracy: 0.8602\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 356.6580 - accuracy: 0.9355\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 669.0479 - accuracy: 0.8925\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 557.3455 - accuracy: 0.9140\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 201.5662 - accuracy: 0.9247\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 119.7410 - accuracy: 0.9570\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 60.0438 - accuracy: 0.9677\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 99.3379 - accuracy: 0.9570\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 36.0981 - accuracy: 0.9785\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "training model 2d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 40204.3398 - accuracy: 0.5591\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 39118.6016 - accuracy: 0.8387\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 12932.6846 - accuracy: 0.8710\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4527.1943 - accuracy: 0.8602\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 600.8102 - accuracy: 0.6989\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 170.5535 - accuracy: 0.7849\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 16.9756 - accuracy: 0.8710\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 13.1156 - accuracy: 0.8817\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 8.3459 - accuracy: 0.8817\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.1182 - accuracy: 0.8495\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.5012 - accuracy: 0.8387\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.7264 - accuracy: 0.7742\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6268 - accuracy: 0.7527\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.3755 - accuracy: 0.8065\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3742 - accuracy: 0.8602\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.3960 - accuracy: 0.8602\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.3604 - accuracy: 0.8602\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.2928 - accuracy: 0.8710\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.2662 - accuracy: 0.8710\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.2402 - accuracy: 0.8817\n",
      "training model 3d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 55ms/step - loss: 13308.6992 - accuracy: 0.6344\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2381.8154 - accuracy: 0.8065\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1543.8530 - accuracy: 0.8172\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 780.3098 - accuracy: 0.8602\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1479.1450 - accuracy: 0.7957\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 770.8641 - accuracy: 0.9247\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 477.1642 - accuracy: 0.9140\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 347.5316 - accuracy: 0.9140\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 692.8217 - accuracy: 0.9355\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 196.8621 - accuracy: 0.9462\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 70.3846 - accuracy: 0.9677\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 336.3640 - accuracy: 0.9462\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 93.1071 - accuracy: 0.9462\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 887.2169 - accuracy: 0.9355\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 827.0037 - accuracy: 0.8602\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 306.0629 - accuracy: 0.9570\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 78.0347 - accuracy: 0.9892\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 307.6258 - accuracy: 0.9140\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 292.6870 - accuracy: 0.9355\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 144.9237 - accuracy: 0.9247\n",
      "training model 4d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 56ms/step - loss: 6306.0913 - accuracy: 0.5269\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5353.7344 - accuracy: 0.8172\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1795.4161 - accuracy: 0.7957\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4623.2988 - accuracy: 0.8817\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3330.3640 - accuracy: 0.8387\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 915.7701 - accuracy: 0.8817\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3134.6553 - accuracy: 0.8710\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1337.9282 - accuracy: 0.9140\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 379.9033 - accuracy: 0.8495\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 117.5687 - accuracy: 0.8925\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 293.4409 - accuracy: 0.9462\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1127.2578 - accuracy: 0.9032\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 335.3660 - accuracy: 0.9247\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 437.4543 - accuracy: 0.9140\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 285.4719 - accuracy: 0.9677\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 468.0746 - accuracy: 0.9677\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7510 - accuracy: 0.9892\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 365.9422 - accuracy: 0.9785\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 472.6395 - accuracy: 0.8817\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 889.2335 - accuracy: 0.9247\n",
      "training model 5d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 58ms/step - loss: 1695.4053 - accuracy: 0.6559\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5988.5825 - accuracy: 0.7742\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5846.8560 - accuracy: 0.7742\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4179.3604 - accuracy: 0.8065\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1210.0642 - accuracy: 0.8710\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1422.6331 - accuracy: 0.8495\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1466.5635 - accuracy: 0.8387\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 982.0273 - accuracy: 0.9140\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1321.7057 - accuracy: 0.8710\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 604.4174 - accuracy: 0.9032\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 257.2411 - accuracy: 0.9032\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 12.3766 - accuracy: 0.9892\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 256.0790 - accuracy: 0.9355\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 60.5678 - accuracy: 0.9677\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1213.3960 - accuracy: 0.8817\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2224.0652 - accuracy: 0.9140\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1331.8751 - accuracy: 0.9355\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1377.2402 - accuracy: 0.8602\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1213.8820 - accuracy: 0.9140\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 469.1442 - accuracy: 0.9462\n",
      "training model 6d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 57ms/step - loss: 4243.2754 - accuracy: 0.5699\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2150.3608 - accuracy: 0.8710\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 5226.7881 - accuracy: 0.6022\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4091.1846 - accuracy: 0.8710\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1836.6630 - accuracy: 0.8710\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2245.8640 - accuracy: 0.7312\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1526.5793 - accuracy: 0.8710\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 635.2020 - accuracy: 0.8925\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 488.5112 - accuracy: 0.9032\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 325.6484 - accuracy: 0.8925\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 96.6148 - accuracy: 0.8602\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 146.3072 - accuracy: 0.9032\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 325.3076 - accuracy: 0.9140\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 143.0538 - accuracy: 0.9140\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.2338 - accuracy: 0.9892\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 148.2128 - accuracy: 0.9032\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 485.2052 - accuracy: 0.9355\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 101.3760 - accuracy: 0.9677\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 337.9211 - accuracy: 0.9462\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 76.9016 - accuracy: 0.9785\n",
      "training model 7d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 57ms/step - loss: 3179.5623 - accuracy: 0.3871\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3906.1440 - accuracy: 0.8387\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2051.3101 - accuracy: 0.8387\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2414.0510 - accuracy: 0.6344\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1409.2510 - accuracy: 0.8710\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 715.3413 - accuracy: 0.7634\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 402.5539 - accuracy: 0.8387\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 380.0399 - accuracy: 0.8817\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 312.8585 - accuracy: 0.7419\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 117.1129 - accuracy: 0.9247\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 116.0632 - accuracy: 0.8495\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 110.2086 - accuracy: 0.8817\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 577.9503 - accuracy: 0.8925\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 121.5545 - accuracy: 0.8495\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 414.7187 - accuracy: 0.8172\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 256.3977 - accuracy: 0.9247\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 250.5989 - accuracy: 0.9140\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 391.7322 - accuracy: 0.8280\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 243.1478 - accuracy: 0.9355\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 896.6768 - accuracy: 0.8925\n"
     ]
    }
   ],
   "source": [
    "TRAINING_EPOCHS = 20\n",
    "\n",
    "# train all models\n",
    "for model, name in zip(models, modelNames):\n",
    "    print(f'training model {name}')\n",
    "    model.fit(X_train, y_train, epochs=TRAINING_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 2533.7888 - accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 90.7096 - accuracy: 0.8750\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2961.5540 - accuracy: 0.5500\n",
      "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_test_function.<locals>.test_function at 0x000001C445104790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1894.4006 - accuracy: 0.8500\n",
      "WARNING:tensorflow:6 out of the last 21 calls to <function Model.make_test_function.<locals>.test_function at 0x000001C445178280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2619.2822 - accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 456.1186 - accuracy: 0.8500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 484.8249 - accuracy: 0.8250\n"
     ]
    }
   ],
   "source": [
    "# get all model accuracy scores on test data\n",
    "scores = [model.evaluate(X_test,y_test)[1] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelNames.insert(0, 'perceptron')\n",
    "scores.insert(0, p.score(X_test, y_test) )\n",
    "\n",
    "plt.bar(modelNames,scores)\n",
    "plt.ylim(0.75, 1.0)\n",
    "plt.ylabel('Test Accuracy (%)') \n",
    "plt.xlabel(str(NODES_PER_HIDDEN_LAYER) + \" nodes per hidden layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C4463BB670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C4463BBE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Model 1 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 2 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 3 Predicted Labels: [0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0\n",
      " 1 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 4 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 5 Predicted Labels: [1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0\n",
      " 0 1 1]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 6 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 7 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "probabilities = [model.predict(X_test) for model in models]\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_labels = [np.argmax(prob, axis=1) for prob in probabilities]\n",
    "\n",
    "# Assuming y_test is your actual labels\n",
    "# Convert y_test to class labels if it's not already in that format\n",
    "# This step depends on how y_test is structured. If it's one-hot encoded, you might need to use np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print predicted and actual labels for each model\n",
    "for i, labels in enumerate(predicted_labels):\n",
    "    print(f\"Model {i+1} Predicted Labels: {labels}\")\n",
    "    print(f\"Actual Labels: {y_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
