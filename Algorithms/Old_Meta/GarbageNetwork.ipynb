{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow import keras\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_src_path = '../../Dataset/MixedDataSet.json'\n",
    "y_src_path = '../../DataBook/Mixed_Data_Analyst.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(x_src_path)\n",
    "dataT = data.isna().sum(axis=1)\n",
    "dataT = dataT.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervision = pd.read_excel(y_src_path)\n",
    "plagiarised_array = df_supervision['Plagiarised'].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.nan_to_num(data.values, nan=0, copy=True).astype(int)\n",
    "y = plagiarised_array\n",
    "ros = SMOTE()\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nanCal = data.isna().sum(axis=1)\n",
    "# print(np.mean(nanCal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
    "#seed 32 results 100% on test score 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 22\n",
      "Number of 1s: 5\n"
     ]
    }
   ],
   "source": [
    "count_0 = 0\n",
    "count_1 = 0\n",
    "\n",
    "for element in y_test:\n",
    "    if element == 0:\n",
    "        count_0 += 1\n",
    "    elif element == 1:\n",
    "        count_1 += 1\n",
    "\n",
    "print(\"Number of 0s:\", count_0)\n",
    "print(\"Number of 1s:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "#     print(\"this stage is \" + str(i))\n",
    "#     count_y_train_1 = np.sum(y_train == 1)\n",
    "#     count_y_test_1 = np.sum(y_test == 1)\n",
    "#     print(count_y_train_1)\n",
    "#     print(count_y_test_1)\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 0.9528301886792453\n",
      "Test data score: 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "p = Perceptron()\n",
    "p.fit(X_train,y_train)\n",
    "\n",
    "print(f\"Training data score: {p.score(X_train, y_train)}\")\n",
    "print(f\"Test data score: {p.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f28b635d30>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix( p.predict(X_test), y_test)\n",
    "# plt.set_cmap()\n",
    "plt.matshow(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        22\n",
      "           1       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.93        27\n",
      "   macro avg       0.88      0.88      0.88        27\n",
      "weighted avg       0.93      0.93      0.93        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions = p.predict(X_test)\n",
    "# for i in range(len(X_test)):\n",
    "#     print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = p.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 1.0\n",
      "Test data score: 0.9259259259259259\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training data score: {train_accuracy}\")\n",
    "print(f\"Test data score: {test_accuracy}\")\n",
    "\n",
    "xpredictions = model.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", xpredictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "4/4 [==============================] - 1s 52ms/step - loss: 4154.7266 - accuracy: 0.6698 - val_loss: 1270.1997 - val_accuracy: 0.8889\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2838.9106 - accuracy: 0.8679 - val_loss: 420.5612 - val_accuracy: 0.8148\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1340.1315 - accuracy: 0.6792 - val_loss: 461.0327 - val_accuracy: 0.9259\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1240.2483 - accuracy: 0.8868 - val_loss: 459.6760 - val_accuracy: 0.9259\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 847.9265 - accuracy: 0.8868 - val_loss: 157.7101 - val_accuracy: 0.8889\n",
      "model eval\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 157.7101 - accuracy: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[157.71005249023438, 0.8888888955116272]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "LOSS_FN = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(optimizer='adam', loss=LOSS_FN, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
    "print(\"model eval\")\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 1, Perceptron: 1 Actual: 1\n",
      "Neural: 1, Perceptron: 1 Actual: 1\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 1, Perceptron: 1 Actual: 1\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "y_pred_train_binary = np.where(y_pred_train >= threshold, 1, 0)\n",
    "y_pred_test_binary = np.where(y_pred_test >= threshold, 1, 0)\n",
    "\n",
    "y_pred_test_binary_flat = y_pred_test_binary.flatten()\n",
    "for pred, actual, percep in zip(y_pred_test_binary_flat, xpredictions, y_test):\n",
    "    print(f\"Neural: {pred}, Perceptron: {percep} Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNames = [\n",
    "    '1d',\n",
    "    '2d',\n",
    "    '3d',\n",
    "    '4d',\n",
    "    '5d',\n",
    "    '6d',\n",
    "    '7d'\n",
    "]\n",
    "\n",
    "NODES_PER_HIDDEN_LAYER = 32\n",
    "outputNode = 1\n",
    "activationFun = 'sigmoid'\n",
    "\n",
    "models = [ \n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(outputNode, activation=activationFun)\n",
    "]),\n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(outputNode, activation=activationFun)\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(outputNode, activation=activationFun)\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(outputNode, activation=activationFun)\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(outputNode, activation=activationFun)\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(outputNode, activation=activationFun)\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(outputNode, activation=activationFun)\n",
    "])\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_FN = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "for model in models:\n",
    "    model.compile(optimizer='adam',loss=LOSS_FN,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model 1d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 407us/step - loss: 1779.9590 - accuracy: 0.7075\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4832.0063 - accuracy: 0.8396\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3847.1460 - accuracy: 0.8585\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1175.2008 - accuracy: 0.7830\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 681.0776 - accuracy: 0.7264\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 404.7888 - accuracy: 0.8962\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 678.9472 - accuracy: 0.8396\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 809.2874 - accuracy: 0.8962\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 263.5480 - accuracy: 0.9057\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 363.6199 - accuracy: 0.8962\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 378.4247 - accuracy: 0.8868\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 203.3446 - accuracy: 0.9245\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 352.6518 - accuracy: 0.7830\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 449.5036 - accuracy: 0.9057\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 404.8156 - accuracy: 0.8868\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 42.7964 - accuracy: 0.9623\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 78.6116 - accuracy: 0.9528\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 99.0313 - accuracy: 0.9245\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 98.3299 - accuracy: 0.8774\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 250.6641 - accuracy: 0.9340\n",
      "training model 2d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 6789.8062 - accuracy: 0.6981\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 4518.1338 - accuracy: 0.5849\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 3362.2524 - accuracy: 0.8868\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 4496.7710 - accuracy: 0.8868\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 1834.9714 - accuracy: 0.8774\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 3379.8892 - accuracy: 0.6321\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 3095.3794 - accuracy: 0.9151\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3382.2461 - accuracy: 0.9151\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1963.5443 - accuracy: 0.8962\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 650.5684 - accuracy: 0.8019\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 328.3011 - accuracy: 0.9623\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1093.1516 - accuracy: 0.8019\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1738.3807 - accuracy: 0.9057\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1505.9830 - accuracy: 0.9151\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1210.8602 - accuracy: 0.8868\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 873.5892 - accuracy: 0.9434\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 827.5534 - accuracy: 0.9057\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 691.9166 - accuracy: 0.8962\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1118.4990 - accuracy: 0.9340\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 531.0639 - accuracy: 0.9245\n",
      "training model 3d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 5ms/step - loss: 1883.6849 - accuracy: 0.5849\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 1293.0341 - accuracy: 0.8679\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 979.2736 - accuracy: 0.8868\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 885.9468 - accuracy: 0.7547\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 568.8217 - accuracy: 0.8868\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 675.7734 - accuracy: 0.8962\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 341.4343 - accuracy: 0.9151\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 148.7939 - accuracy: 0.7925\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 177.8995 - accuracy: 0.9434\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 163.1750 - accuracy: 0.9340\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 415.5574 - accuracy: 0.6698\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 457.7087 - accuracy: 0.9151\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 431.3176 - accuracy: 0.9245\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 389.9744 - accuracy: 0.8585\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 280.0468 - accuracy: 0.8396\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 165.8086 - accuracy: 0.9528\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 88.4527 - accuracy: 0.9245\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 76.4835 - accuracy: 0.8774\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 154.2326 - accuracy: 0.9245\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 89.3474 - accuracy: 0.9151\n",
      "training model 4d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 5ms/step - loss: 300.4152 - accuracy: 0.5943\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 693.0075 - accuracy: 0.8396\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 615.2203 - accuracy: 0.8113\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1232.0243 - accuracy: 0.8585\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 571.2446 - accuracy: 0.7358\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 213.4427 - accuracy: 0.7547\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 233.5322 - accuracy: 0.8962\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 402.7140 - accuracy: 0.7736\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 398.6374 - accuracy: 0.8868\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 156.6245 - accuracy: 0.8868\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 168.9207 - accuracy: 0.7642\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 200.5556 - accuracy: 0.9057\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 151.8360 - accuracy: 0.8962\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 76.2496 - accuracy: 0.8962\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 67.4981 - accuracy: 0.9151\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 66.9212 - accuracy: 0.8208\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 47.0722 - accuracy: 0.9340\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 28.8322 - accuracy: 0.8774\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 27.8549 - accuracy: 0.9623\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 19.6162 - accuracy: 0.9528\n",
      "training model 5d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 7ms/step - loss: 668.2589 - accuracy: 0.6792\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 231.3542 - accuracy: 0.8208\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 204.0631 - accuracy: 0.6698\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 412.2656 - accuracy: 0.8868\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 418.7414 - accuracy: 0.7547\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 165.8896 - accuracy: 0.8774\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 135.1191 - accuracy: 0.8491\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 61.6799 - accuracy: 0.8208\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 43.5670 - accuracy: 0.9151\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 62.3111 - accuracy: 0.8585\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.1098 - accuracy: 0.8679\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 211.7616 - accuracy: 0.8868\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 391.7610 - accuracy: 0.8679\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 243.0515 - accuracy: 0.7358\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 45.6200 - accuracy: 0.9151\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 84.1656 - accuracy: 0.8962\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 50.8185 - accuracy: 0.8962\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 16.4646 - accuracy: 0.9340\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 27.0157 - accuracy: 0.9434\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 18.4423 - accuracy: 0.9623\n",
      "training model 6d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 4ms/step - loss: 141.9118 - accuracy: 0.5094\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 156.9872 - accuracy: 0.7453\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 287.1192 - accuracy: 0.8585\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 191.1198 - accuracy: 0.7547\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 105.9837 - accuracy: 0.6981\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 363.4528 - accuracy: 0.8774\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 255.5788 - accuracy: 0.8585\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 219.0827 - accuracy: 0.6509\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 150.7335 - accuracy: 0.8774\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 99.5428 - accuracy: 0.8679\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 69.1927 - accuracy: 0.7170\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 65.3478 - accuracy: 0.8868\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 30.0134 - accuracy: 0.8396\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 16.5315 - accuracy: 0.9057\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 25.1575 - accuracy: 0.9340\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 12.7587 - accuracy: 0.9245\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 10.9700 - accuracy: 0.9340\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5.2244 - accuracy: 0.9528\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2.9301 - accuracy: 0.9340\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 7.0050 - accuracy: 0.9340\n",
      "training model 7d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 5ms/step - loss: 106.1385 - accuracy: 0.8491\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 59.1975 - accuracy: 0.7736\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 41.0013 - accuracy: 0.8113\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 35.7980 - accuracy: 0.8396\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 12.9110 - accuracy: 0.7925\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.6232 - accuracy: 0.7830\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 29.9518 - accuracy: 0.8962\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 13.7810 - accuracy: 0.7547\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 6.1455 - accuracy: 0.9057\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 13.2628 - accuracy: 0.8774\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 6.8618 - accuracy: 0.8679\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2.8302 - accuracy: 0.8962\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.3296 - accuracy: 0.8868\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 14.4936 - accuracy: 0.7075\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 12.7297 - accuracy: 0.8962\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 10.8071 - accuracy: 0.8396\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 6.6888 - accuracy: 0.5943\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 6.7933 - accuracy: 0.8962\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.0146 - accuracy: 0.8679\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.7280 - accuracy: 0.7170\n"
     ]
    }
   ],
   "source": [
    "TRAINING_EPOCHS = 20\n",
    "\n",
    "# train all models\n",
    "for model, name in zip(models, modelNames):\n",
    "    print(f'training model {name}')\n",
    "    model.fit(X_train, y_train, epochs=TRAINING_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step - loss: 179.9210 - accuracy: 0.9259\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 309.6008 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 230.7570 - accuracy: 0.7778\n",
      "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F2952AD280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 23.7464 - accuracy: 0.8519\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F2952AD790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 241.4734 - accuracy: 0.5926\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 51.2878 - accuracy: 0.7037\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5548 - accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "# get all model accuracy scores on test data\n",
    "scores = [model.evaluate(X_test,y_test)[1] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelNames.insert(0, 'perceptron')\n",
    "scores.insert(0, p.score(X_test, y_test) )\n",
    "\n",
    "plt.bar(modelNames,scores)\n",
    "plt.ylim(0.75, 1.0)\n",
    "plt.ylabel('Test Accuracy (%)') \n",
    "plt.xlabel(str(NODES_PER_HIDDEN_LAYER) + \" nodes per hidden layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F29650DE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F28B64F8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Model 1 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Model 2 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Model 3 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Model 4 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Model 5 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Model 6 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Model 7 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "probabilities = [model.predict(X_test) for model in models]\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_labels = [np.argmax(prob, axis=1) for prob in probabilities]\n",
    "\n",
    "# Assuming y_test is your actual labels\n",
    "# Convert y_test to class labels if it's not already in that format\n",
    "# This step depends on how y_test is structured. If it's one-hot encoded, you might need to use np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print predicted and actual labels for each model\n",
    "for i, labels in enumerate(predicted_labels):\n",
    "    print(f\"Model {i+1} Predicted Labels: {labels}\")\n",
    "    print(f\"Actual Labels: {y_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
