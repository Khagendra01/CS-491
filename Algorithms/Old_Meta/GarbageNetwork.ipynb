{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow import keras\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_src_path = '../../Dataset/MixedDataSet.json'\n",
    "y_src_path = '../../DataBook/Mixed_Data_Analyst.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(x_src_path)\n",
    "data = data.iloc[:, :-59022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervision = pd.read_excel(y_src_path)\n",
    "plagiarised_array = df_supervision['Plagiarised'].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.nan_to_num(data.values, nan=0, copy=True).astype(int)\n",
    "y = plagiarised_array\n",
    "ros = SMOTE()\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nanCal = data.isna().sum(axis=1)\n",
    "# print(np.mean(nanCal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
    "#seed 32 results 100% on test score 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 22\n",
      "Number of 1s: 5\n"
     ]
    }
   ],
   "source": [
    "count_0 = 0\n",
    "count_1 = 0\n",
    "\n",
    "for element in y_test:\n",
    "    if element == 0:\n",
    "        count_0 += 1\n",
    "    elif element == 1:\n",
    "        count_1 += 1\n",
    "\n",
    "print(\"Number of 0s:\", count_0)\n",
    "print(\"Number of 1s:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "#     print(\"this stage is \" + str(i))\n",
    "#     count_y_train_1 = np.sum(y_train == 1)\n",
    "#     count_y_test_1 = np.sum(y_test == 1)\n",
    "#     print(count_y_train_1)\n",
    "#     print(count_y_test_1)\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 0.9528301886792453\n",
      "Test data score: 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "p = Perceptron()\n",
    "p.fit(X_train,y_train)\n",
    "\n",
    "print(f\"Training data score: {p.score(X_train, y_train)}\")\n",
    "print(f\"Test data score: {p.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        22\n",
      "           1       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.93        27\n",
      "   macro avg       0.88      0.88      0.88        27\n",
      "weighted avg       0.93      0.93      0.93        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions = p.predict(X_test)\n",
    "# for i in range(len(X_test)):\n",
    "#     print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = p.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 1.0\n",
      "Test data score: 0.9259259259259259\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training data score: {train_accuracy}\")\n",
    "print(f\"Test data score: {test_accuracy}\")\n",
    "\n",
    "xpredictions = model.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", xpredictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "4/4 [==============================] - 1s 55ms/step - loss: 2672.3792 - accuracy: 0.7642 - val_loss: 497.0478 - val_accuracy: 0.5556\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2544.3733 - accuracy: 0.5283 - val_loss: 829.6368 - val_accuracy: 0.9259\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3494.3794 - accuracy: 0.8774 - val_loss: 887.1880 - val_accuracy: 0.9259\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2943.5083 - accuracy: 0.8491 - val_loss: 478.0779 - val_accuracy: 0.8519\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 998.1370 - accuracy: 0.7925 - val_loss: 606.7242 - val_accuracy: 0.6296\n",
      "model eval\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 606.7242 - accuracy: 0.6296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[606.7241821289062, 0.6296296119689941]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "LOSS_FN = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(optimizer='adam', loss=LOSS_FN, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
    "print(\"model eval\")\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 1, Perceptron: 1 Actual: 1\n",
      "Neural: 1, Perceptron: 1 Actual: 1\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 1 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 1, Perceptron: 1 Actual: 1\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n",
      "Neural: 0, Perceptron: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "y_pred_train_binary = np.where(y_pred_train >= threshold, 1, 0)\n",
    "y_pred_test_binary = np.where(y_pred_test >= threshold, 1, 0)\n",
    "\n",
    "y_pred_test_binary_flat = y_pred_test_binary.flatten()\n",
    "for pred, actual, percep in zip(y_pred_test_binary_flat, xpredictions, y_test):\n",
    "    print(f\"Neural: {pred}, Perceptron: {percep} Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNames = [\n",
    "    '1d',\n",
    "    '2d',\n",
    "    '3d',\n",
    "    '4d',\n",
    "    '5d',\n",
    "    '6d',\n",
    "    '7d'\n",
    "]\n",
    "\n",
    "NODES_PER_HIDDEN_LAYER = 128\n",
    "\n",
    "models = [ \n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(16689,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_FN = keras.losses.sparse_categorical_crossentropy\n",
    "\n",
    "for model in models:\n",
    "    model.compile(optimizer='adam',loss=LOSS_FN,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model 1d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 11655.8584 - accuracy: 0.4434\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 6830.8403 - accuracy: 0.8679\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 10434.5498 - accuracy: 0.8679\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 10055.3457 - accuracy: 0.8679\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 7500.2568 - accuracy: 0.8679\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 4406.7632 - accuracy: 0.8491\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3576.8945 - accuracy: 0.7547\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2620.8794 - accuracy: 0.6792\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2541.1074 - accuracy: 0.8679\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2895.8220 - accuracy: 0.8962\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1739.3099 - accuracy: 0.8774\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 813.7206 - accuracy: 0.8208\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 871.0912 - accuracy: 0.9057\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 403.3752 - accuracy: 0.9151\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 857.2279 - accuracy: 0.8208\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 566.0737 - accuracy: 0.9057\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 435.8729 - accuracy: 0.9245\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 425.6805 - accuracy: 0.8962\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 120.2108 - accuracy: 0.9528\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 257.1967 - accuracy: 0.9434\n",
      "training model 2d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 16433.6680 - accuracy: 0.6226\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 11942.3701 - accuracy: 0.8585\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2752.2524 - accuracy: 0.6698\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1849.4366 - accuracy: 0.8585\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1176.8678 - accuracy: 0.8774\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 350.0464 - accuracy: 0.9057\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1114.4673 - accuracy: 0.8208\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1300.2067 - accuracy: 0.8962\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 546.3135 - accuracy: 0.7736\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 834.7245 - accuracy: 0.9057\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1272.3169 - accuracy: 0.9057\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 671.2236 - accuracy: 0.8962\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 325.3221 - accuracy: 0.9057\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 180.2211 - accuracy: 0.9340\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 278.0936 - accuracy: 0.8774\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 240.1405 - accuracy: 0.9340\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 196.8423 - accuracy: 0.9057\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 215.9929 - accuracy: 0.9717\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 449.0640 - accuracy: 0.9245\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 206.1997 - accuracy: 0.9151\n",
      "training model 3d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6486.7275 - accuracy: 0.6792\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8403.9365 - accuracy: 0.6415\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3126.4878 - accuracy: 0.8774\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1501.4241 - accuracy: 0.8962\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1622.4458 - accuracy: 0.6509\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1038.9382 - accuracy: 0.9057\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 550.0369 - accuracy: 0.8774\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 324.8310 - accuracy: 0.9340\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 382.9409 - accuracy: 0.8962\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 254.4749 - accuracy: 0.9057\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 195.9770 - accuracy: 0.8962\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 160.8475 - accuracy: 0.8962\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 309.2668 - accuracy: 0.9245\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 100.0299 - accuracy: 0.9340\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 223.4693 - accuracy: 0.9340\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 98.6671 - accuracy: 0.9340\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 149.4335 - accuracy: 0.9245\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 33.9186 - accuracy: 0.9717\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 168.1782 - accuracy: 0.9151\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 99.1822 - accuracy: 0.9528\n",
      "training model 4d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 15ms/step - loss: 3149.1973 - accuracy: 0.6321\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5942.3555 - accuracy: 0.8774\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4475.9727 - accuracy: 0.8302\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1719.2721 - accuracy: 0.7830\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1705.2421 - accuracy: 0.8208\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1332.8623 - accuracy: 0.8679\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1321.5781 - accuracy: 0.8208\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 845.3625 - accuracy: 0.7358\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 705.4247 - accuracy: 0.8679\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1257.2827 - accuracy: 0.7925\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1317.5947 - accuracy: 0.8962\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 358.1290 - accuracy: 0.7736\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 698.7411 - accuracy: 0.9057\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 458.6619 - accuracy: 0.9151\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 441.0740 - accuracy: 0.7453\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1787.9779 - accuracy: 0.8774\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1209.2424 - accuracy: 0.9245\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 635.6675 - accuracy: 0.7358\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 878.9234 - accuracy: 0.9245\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1215.1199 - accuracy: 0.9057\n",
      "training model 5d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 15ms/step - loss: 1183.7522 - accuracy: 0.6321\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 696.2993 - accuracy: 0.6604\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1085.7703 - accuracy: 0.8113\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1140.2689 - accuracy: 0.8774\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1309.3961 - accuracy: 0.8396\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 635.3101 - accuracy: 0.6698\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 287.5196 - accuracy: 0.7830\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 335.8627 - accuracy: 0.8491\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 253.8854 - accuracy: 0.8491\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 427.4616 - accuracy: 0.7547\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 706.7385 - accuracy: 0.8868\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 403.8233 - accuracy: 0.8774\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 367.2140 - accuracy: 0.7547\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 480.2093 - accuracy: 0.7453\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 786.6702 - accuracy: 0.8962\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 476.1465 - accuracy: 0.9151\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 664.1649 - accuracy: 0.7170\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 234.5364 - accuracy: 0.9340\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 445.0543 - accuracy: 0.7830\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 867.1098 - accuracy: 0.8962\n",
      "training model 6d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 16ms/step - loss: 1515.1807 - accuracy: 0.5566\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1006.6456 - accuracy: 0.8585\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 653.7111 - accuracy: 0.6415\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 905.1006 - accuracy: 0.8774\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 354.4721 - accuracy: 0.7453\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 880.2557 - accuracy: 0.8774\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 841.2863 - accuracy: 0.8774\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 558.4534 - accuracy: 0.6226\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 683.0692 - accuracy: 0.8679\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 449.5122 - accuracy: 0.8868\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 185.7269 - accuracy: 0.6509\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 151.6480 - accuracy: 0.9151\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 41.7157 - accuracy: 0.8396\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 116.6391 - accuracy: 0.8585\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 146.3622 - accuracy: 0.8868\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 206.4239 - accuracy: 0.7925\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 217.8160 - accuracy: 0.9151\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 204.9756 - accuracy: 0.7358\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 186.7536 - accuracy: 0.8585\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 119.5641 - accuracy: 0.8868\n",
      "training model 7d\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 15ms/step - loss: 405.9423 - accuracy: 0.6226\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1975.6327 - accuracy: 0.8585\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1081.9775 - accuracy: 0.6509\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 627.0805 - accuracy: 0.8019\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 273.1041 - accuracy: 0.6887\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 917.0229 - accuracy: 0.8679\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 370.3723 - accuracy: 0.8113\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 157.2781 - accuracy: 0.8585\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 344.5948 - accuracy: 0.7547\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 503.8930 - accuracy: 0.8774\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 251.9061 - accuracy: 0.6981\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 140.5074 - accuracy: 0.8774\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 79.9852 - accuracy: 0.7830\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 423.8421 - accuracy: 0.8868\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 235.8146 - accuracy: 0.8019\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 121.9461 - accuracy: 0.9151\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 144.5357 - accuracy: 0.8113\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 312.4747 - accuracy: 0.8774\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 128.3148 - accuracy: 0.7358\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 40.8520 - accuracy: 0.8679\n"
     ]
    }
   ],
   "source": [
    "TRAINING_EPOCHS = 20\n",
    "\n",
    "# train all models\n",
    "for model, name in zip(models, modelNames):\n",
    "    print(f'training model {name}')\n",
    "    model.fit(X_train, y_train, epochs=TRAINING_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step - loss: 311.7361 - accuracy: 0.9259\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 393.4197 - accuracy: 0.8519\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 182.9208 - accuracy: 0.8148\n",
      "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x0000024E083AC940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 345.5291 - accuracy: 0.9259\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000024E0938E0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 414.0207 - accuracy: 0.9630\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 46.0778 - accuracy: 0.8148\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 586.7109 - accuracy: 0.4815\n"
     ]
    }
   ],
   "source": [
    "# get all model accuracy scores on test data\n",
    "scores = [model.evaluate(X_test,y_test)[1] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelNames.insert(0, 'perceptron')\n",
    "scores.insert(0, p.score(X_test, y_test) )\n",
    "\n",
    "plt.bar(modelNames,scores)\n",
    "plt.ylim(0.75, 1.0)\n",
    "plt.ylabel('Test Accuracy (%)') \n",
    "plt.xlabel(str(NODES_PER_HIDDEN_LAYER) + \" nodes per hidden layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024E0A4EC820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024E0A54C280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Model 1 Predicted Labels: [0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Model 2 Predicted Labels: [0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Model 3 Predicted Labels: [0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Model 4 Predicted Labels: [0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Model 5 Predicted Labels: [0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Model 6 Predicted Labels: [0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Model 7 Predicted Labels: [0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1]\n",
      "Actual Labels: [0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "probabilities = [model.predict(X_test) for model in models]\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_labels = [np.argmax(prob, axis=1) for prob in probabilities]\n",
    "\n",
    "# Assuming y_test is your actual labels\n",
    "# Convert y_test to class labels if it's not already in that format\n",
    "# This step depends on how y_test is structured. If it's one-hot encoded, you might need to use np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print predicted and actual labels for each model\n",
    "for i, labels in enumerate(predicted_labels):\n",
    "    print(f\"Model {i+1} Predicted Labels: {labels}\")\n",
    "    print(f\"Actual Labels: {y_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
