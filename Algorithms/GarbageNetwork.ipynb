{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow import keras\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_src_path = '../Dataset/MixedDataSet.json'\n",
    "y_src_path = '../DataBook/Mixed_Data_Analyst.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(x_src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervision = pd.read_excel(y_src_path)\n",
    "plagiarised_array = df_supervision['Plagiarised'].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.nan_to_num(data.values, nan=0, copy=True).astype(int)\n",
    "y = plagiarised_array\n",
    "ros = SMOTE()\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=14)\n",
    "#seed 32 results 100% on test score 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 34\n",
      "Number of 1s: 6\n"
     ]
    }
   ],
   "source": [
    "count_0 = 0\n",
    "count_1 = 0\n",
    "\n",
    "for element in y_test:\n",
    "    if element == 0:\n",
    "        count_0 += 1\n",
    "    elif element == 1:\n",
    "        count_1 += 1\n",
    "\n",
    "print(\"Number of 0s:\", count_0)\n",
    "print(\"Number of 1s:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "#     print(\"this stage is \" + str(i))\n",
    "#     count_y_train_1 = np.sum(y_train == 1)\n",
    "#     count_y_test_1 = np.sum(y_test == 1)\n",
    "#     print(count_y_train_1)\n",
    "#     print(count_y_test_1)\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 1.0\n",
      "Test data score: 0.7\n"
     ]
    }
   ],
   "source": [
    "p = Perceptron()\n",
    "p.fit(X_train,y_train)\n",
    "\n",
    "print(f\"Training data score: {p.score(X_train, y_train)}\")\n",
    "print(f\"Test data score: {p.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82        34\n",
      "           1       0.12      0.17      0.14         6\n",
      "\n",
      "    accuracy                           0.70        40\n",
      "   macro avg       0.48      0.48      0.48        40\n",
      "weighted avg       0.74      0.70      0.72        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions = p.predict(X_test)\n",
    "# for i in range(len(X_test)):\n",
    "#     print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = p.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNames = [\n",
    "    '1d',\n",
    "    '2d',\n",
    "    '3d',\n",
    "    '4d',\n",
    "    '5d',\n",
    "    '6d',\n",
    "    '7d'\n",
    "]\n",
    "\n",
    "NODES_PER_HIDDEN_LAYER = 128\n",
    "\n",
    "models = [ \n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_FN = keras.losses.sparse_categorical_crossentropy\n",
    "\n",
    "for model in models:\n",
    "    model.compile(optimizer='adam',loss=LOSS_FN,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model 1d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9332.2256 - accuracy: 0.6022\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 17867.7227 - accuracy: 0.8495\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 14732.8525 - accuracy: 0.8710\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7638.6655 - accuracy: 0.9140\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9294.0205 - accuracy: 0.7957\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5155.2988 - accuracy: 0.7849\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4537.1069 - accuracy: 0.7849\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 749.6462 - accuracy: 0.8710\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1778.6053 - accuracy: 0.8602\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 899.0941 - accuracy: 0.9032\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 832.5223 - accuracy: 0.8925\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 221.1270 - accuracy: 0.9247\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 557.8694 - accuracy: 0.8710\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 110.1229 - accuracy: 0.9462\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 130.7067 - accuracy: 0.9785\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 303.8438 - accuracy: 0.9462\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 137.0108 - accuracy: 0.9570\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 60.1213 - accuracy: 0.9570\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 27.8019 - accuracy: 0.9570\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8648 - accuracy: 0.9892\n",
      "training model 2d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 58ms/step - loss: 15694.4082 - accuracy: 0.6559\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 33263.4219 - accuracy: 0.8602\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 18310.3633 - accuracy: 0.8710\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 8988.2461 - accuracy: 0.7204\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2573.8186 - accuracy: 0.7957\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2741.0916 - accuracy: 0.8710\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2876.8347 - accuracy: 0.8817\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2451.2695 - accuracy: 0.8925\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1799.9866 - accuracy: 0.9140\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 845.4694 - accuracy: 0.9032\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 458.9567 - accuracy: 0.8925\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 463.8670 - accuracy: 0.8602\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 70.2466 - accuracy: 0.9462\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 198.4084 - accuracy: 0.9355\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 558.3076 - accuracy: 0.8925\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 57.8672 - accuracy: 0.9570\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 59.8410 - accuracy: 0.9570\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 291.4350 - accuracy: 0.9355\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 14.3535 - accuracy: 0.9892\n",
      "training model 3d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 57ms/step - loss: 12976.3818 - accuracy: 0.6882\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 9984.0547 - accuracy: 0.7849\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1455.4756 - accuracy: 0.7527\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2456.7573 - accuracy: 0.8602\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2808.4351 - accuracy: 0.8817\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1838.2345 - accuracy: 0.7312\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 556.2839 - accuracy: 0.8817\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 689.1438 - accuracy: 0.9355\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 693.9801 - accuracy: 0.9247\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 911.8995 - accuracy: 0.9462\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 763.5187 - accuracy: 0.9462\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 180.1678 - accuracy: 0.9677\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 75.0101 - accuracy: 0.9677\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 147.8563 - accuracy: 0.9677\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 11.9641 - accuracy: 0.9785\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 60.8954 - accuracy: 0.9892\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 402.2326 - accuracy: 0.9140\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 561.0048 - accuracy: 0.9355\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1109.2120 - accuracy: 0.9677\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 649.7125 - accuracy: 0.9355\n",
      "training model 4d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 58ms/step - loss: 12502.5781 - accuracy: 0.6452\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 15975.8525 - accuracy: 0.6022\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4076.8303 - accuracy: 0.8925\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5354.2251 - accuracy: 0.8602\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2566.5811 - accuracy: 0.8065\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1521.0076 - accuracy: 0.8817\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 982.0952 - accuracy: 0.8602\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 179.8758 - accuracy: 0.9247\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 291.6868 - accuracy: 0.9140\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 435.5545 - accuracy: 0.9140\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.0379e-06 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 299.8555 - accuracy: 0.9140\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 419.5861 - accuracy: 0.9355\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 354.6953 - accuracy: 0.9785\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 219.0496 - accuracy: 0.9785\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 73.6670 - accuracy: 0.9785\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 82.5334 - accuracy: 0.9462\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 435.3424 - accuracy: 0.9140\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 165.4097 - accuracy: 0.9247\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 219.0710 - accuracy: 0.9462\n",
      "training model 5d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 59ms/step - loss: 5538.1851 - accuracy: 0.3441\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1725.4617 - accuracy: 0.8495\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 579.5148 - accuracy: 0.8710\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2640.3162 - accuracy: 0.6559\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2169.4829 - accuracy: 0.8602\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1074.5519 - accuracy: 0.8817\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1065.6024 - accuracy: 0.8065\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 599.3162 - accuracy: 0.8280\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1276.0857 - accuracy: 0.8817\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1665.9048 - accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1357.4883 - accuracy: 0.9032\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3076.3601 - accuracy: 0.8602\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1783.3344 - accuracy: 0.8925\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 705.4595 - accuracy: 0.8387\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 901.1353 - accuracy: 0.8280\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 661.7307 - accuracy: 0.9355\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 658.6362 - accuracy: 0.9570\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 509.2547 - accuracy: 0.9355\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 130.2423 - accuracy: 0.9355\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 212.0387 - accuracy: 0.9355\n",
      "training model 6d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 60ms/step - loss: 1087.4222 - accuracy: 0.5806\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 6386.9077 - accuracy: 0.6237\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3065.7390 - accuracy: 0.8495\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2146.7778 - accuracy: 0.7742\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1133.9720 - accuracy: 0.7204\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2670.6318 - accuracy: 0.8710\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2154.8481 - accuracy: 0.8817\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 792.3641 - accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 345.0487 - accuracy: 0.9032\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 635.3947 - accuracy: 0.8817\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2047.1794 - accuracy: 0.9032\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1074.6996 - accuracy: 0.8280\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1375.7122 - accuracy: 0.8710\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 936.9975 - accuracy: 0.8925\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 545.7930 - accuracy: 0.8602\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 370.1663 - accuracy: 0.9247\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 97.0581 - accuracy: 0.8925\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 99.8325 - accuracy: 0.8925\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 104.1351 - accuracy: 0.9032\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 163.6528 - accuracy: 0.9785\n",
      "training model 7d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 58ms/step - loss: 541.4262 - accuracy: 0.4194\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1905.0995 - accuracy: 0.7849\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4476.5264 - accuracy: 0.8602\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1803.1084 - accuracy: 0.7742\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 792.5065 - accuracy: 0.8172\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1590.2354 - accuracy: 0.8710\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 771.3301 - accuracy: 0.6559\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 411.2695 - accuracy: 0.8817\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 652.1554 - accuracy: 0.8710\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 582.6949 - accuracy: 0.8495\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 966.7742 - accuracy: 0.8710\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 268.1440 - accuracy: 0.7849\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1062.9050 - accuracy: 0.8280\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 515.4506 - accuracy: 0.8280\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 393.5082 - accuracy: 0.9032\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 483.5066 - accuracy: 0.9032\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 188.2843 - accuracy: 0.8495\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 168.9756 - accuracy: 0.8602\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 134.3402 - accuracy: 0.9247\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 194.8976 - accuracy: 0.8925\n"
     ]
    }
   ],
   "source": [
    "TRAINING_EPOCHS = 20\n",
    "\n",
    "# train all models\n",
    "for model, name in zip(models, modelNames):\n",
    "    print(f'training model {name}')\n",
    "    model.fit(X_train, y_train, epochs=TRAINING_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 1912.0720 - accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2236.3425 - accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1290.0892 - accuracy: 0.6000\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1097.9204 - accuracy: 0.8500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 403.4517 - accuracy: 0.8750\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 189.9105 - accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 94.3863 - accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "# get all model accuracy scores on test data\n",
    "scores = [model.evaluate(X_test,y_test)[1] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelNames.insert(0, 'perceptron')\n",
    "scores.insert(0, p.score(X_test, y_test) )\n",
    "\n",
    "plt.bar(modelNames,scores)\n",
    "plt.ylim(0.75, 1.0)\n",
    "plt.ylabel('Test Accuracy (%)') \n",
    "plt.xlabel(str(NODES_PER_HIDDEN_LAYER) + \" nodes per hidden layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Model 1 Predicted Labels: [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 2 Predicted Labels: [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 3 Predicted Labels: [0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0\n",
      " 1 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 4 Predicted Labels: [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 5 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 6 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 7 Predicted Labels: [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "probabilities = [model.predict(X_test) for model in models]\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_labels = [np.argmax(prob, axis=1) for prob in probabilities]\n",
    "\n",
    "# Assuming y_test is your actual labels\n",
    "# Convert y_test to class labels if it's not already in that format\n",
    "# This step depends on how y_test is structured. If it's one-hot encoded, you might need to use np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print predicted and actual labels for each model\n",
    "for i, labels in enumerate(predicted_labels):\n",
    "    print(f\"Model {i+1} Predicted Labels: {labels}\")\n",
    "    print(f\"Actual Labels: {y_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
