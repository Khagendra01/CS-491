{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow import keras\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_src_path = '../Dataset/MixedDataSet.json'\n",
    "y_src_path = '../DataBook/Mixed_Data_Analyst.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(x_src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervision = pd.read_excel(y_src_path)\n",
    "plagiarised_array = df_supervision['Plagiarised'].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.nan_to_num(data.values, nan=0, copy=True).astype(int)\n",
    "y = plagiarised_array\n",
    "ros = SMOTE()\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=14)\n",
    "#seed 32 results 100% on test score 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 34\n",
      "Number of 1s: 6\n"
     ]
    }
   ],
   "source": [
    "count_0 = 0\n",
    "count_1 = 0\n",
    "\n",
    "for element in y_test:\n",
    "    if element == 0:\n",
    "        count_0 += 1\n",
    "    elif element == 1:\n",
    "        count_1 += 1\n",
    "\n",
    "print(\"Number of 0s:\", count_0)\n",
    "print(\"Number of 1s:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "#     print(\"this stage is \" + str(i))\n",
    "#     count_y_train_1 = np.sum(y_train == 1)\n",
    "#     count_y_test_1 = np.sum(y_test == 1)\n",
    "#     print(count_y_train_1)\n",
    "#     print(count_y_test_1)\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 1.0\n",
      "Test data score: 0.7\n"
     ]
    }
   ],
   "source": [
    "p = Perceptron()\n",
    "p.fit(X_train,y_train)\n",
    "\n",
    "print(f\"Training data score: {p.score(X_train, y_train)}\")\n",
    "print(f\"Test data score: {p.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82        34\n",
      "           1       0.12      0.17      0.14         6\n",
      "\n",
      "    accuracy                           0.70        40\n",
      "   macro avg       0.48      0.48      0.48        40\n",
      "weighted avg       0.74      0.70      0.72        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions = p.predict(X_test)\n",
    "# for i in range(len(X_test)):\n",
    "#     print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = p.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 1.0\n",
      "Test data score: 0.925\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training data score: {train_accuracy}\")\n",
    "print(f\"Test data score: {test_accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelNames = [\n",
    "    '1d',\n",
    "    '2d',\n",
    "    '3d',\n",
    "    '4d',\n",
    "    '5d',\n",
    "    '6d',\n",
    "    '7d'\n",
    "]\n",
    "\n",
    "NODES_PER_HIDDEN_LAYER = 128\n",
    "\n",
    "models = [ \n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(75711,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOSS_FN = keras.losses.sparse_categorical_crossentropy\n",
    "\n",
    "for model in models:\n",
    "    model.compile(optimizer='adam',loss=LOSS_FN,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model 1d\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\K-Gen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 11057.9775 - accuracy: 0.5699\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 0s/step - loss: 13976.7393 - accuracy: 0.8387\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 0s/step - loss: 10993.0654 - accuracy: 0.8710\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 9046.8564 - accuracy: 0.8817\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 0s/step - loss: 6591.5791 - accuracy: 0.8387\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 0s/step - loss: 4831.6431 - accuracy: 0.7957\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 0s/step - loss: 4978.2495 - accuracy: 0.7527\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1380.7306 - accuracy: 0.8602\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 696.8505 - accuracy: 0.9247\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 0s/step - loss: 3110.5605 - accuracy: 0.8817\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 0s/step - loss: 3003.3682 - accuracy: 0.9032\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1599.8097 - accuracy: 0.9032\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 399.7800 - accuracy: 0.9032\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 347.6583 - accuracy: 0.9032\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 67.8504 - accuracy: 0.9785\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 0s/step - loss: 190.3171 - accuracy: 0.9570\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 322.0407 - accuracy: 0.9462\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 37.4763 - accuracy: 0.9677\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 0s/step - loss: 102.5351 - accuracy: 0.9570\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 0s/step - loss: 141.1445 - accuracy: 0.9570\n",
      "training model 2d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 54ms/step - loss: 20750.3906 - accuracy: 0.7204\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 16771.1484 - accuracy: 0.8495\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8444.8623 - accuracy: 0.8387\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3887.8650 - accuracy: 0.6989\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 541.5801 - accuracy: 0.8065\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 522.7636 - accuracy: 0.8925\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 631.8166 - accuracy: 0.9140\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 538.4820 - accuracy: 0.9032\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 304.0835 - accuracy: 0.8710\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 143.9113 - accuracy: 0.9355\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 113.2894 - accuracy: 0.9140\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 81.7829 - accuracy: 0.9247\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 40.9502 - accuracy: 0.9462\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 132.0166 - accuracy: 0.9355\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 67.5262 - accuracy: 0.9247\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 2.6206 - accuracy: 0.9677\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0297 - accuracy: 0.9892\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 78.6750 - accuracy: 0.9462\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 25.8194 - accuracy: 0.9677\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 72.4583 - accuracy: 0.9355\n",
      "training model 3d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 55ms/step - loss: 7682.0122 - accuracy: 0.5914\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 6530.9888 - accuracy: 0.7527\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3846.3171 - accuracy: 0.8710\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 4153.0376 - accuracy: 0.8710\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2481.2390 - accuracy: 0.7527\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 3936.3672 - accuracy: 0.8280\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 5012.3784 - accuracy: 0.8602\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5007.7822 - accuracy: 0.9032\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2597.1597 - accuracy: 0.8602\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1059.5095 - accuracy: 0.8495\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1014.1844 - accuracy: 0.9032\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1027.6857 - accuracy: 0.8710\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 205.6509 - accuracy: 0.9677\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 137.5860 - accuracy: 0.9677\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 185.8891 - accuracy: 0.9570\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 87.8696 - accuracy: 0.9570\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 133.8997 - accuracy: 0.9570\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 110.4077 - accuracy: 0.9570\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 27.2615 - accuracy: 0.9785\n",
      "training model 4d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 55ms/step - loss: 3653.1899 - accuracy: 0.5699\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 4279.5249 - accuracy: 0.6559\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2368.4924 - accuracy: 0.8925\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1487.7552 - accuracy: 0.7849\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2392.5535 - accuracy: 0.8172\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 513.8507 - accuracy: 0.8925\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1670.1643 - accuracy: 0.7419\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1136.5295 - accuracy: 0.8925\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1113.3274 - accuracy: 0.9032\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 531.9213 - accuracy: 0.9247\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 84.6470 - accuracy: 0.9247\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 930.5315 - accuracy: 0.9140\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2033.1243 - accuracy: 0.8817\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 956.5281 - accuracy: 0.8172\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 491.2444 - accuracy: 0.8817\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1708.5947 - accuracy: 0.9140\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1729.9829 - accuracy: 0.9032\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 842.3381 - accuracy: 0.9677\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 625.9116 - accuracy: 0.8602\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 298.7641 - accuracy: 0.9247\n",
      "training model 5d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 58ms/step - loss: 3135.4368 - accuracy: 0.4946\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 5190.1753 - accuracy: 0.8710\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2800.1831 - accuracy: 0.8495\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2432.2998 - accuracy: 0.6237\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1825.5492 - accuracy: 0.8602\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2514.2932 - accuracy: 0.8925\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1136.1052 - accuracy: 0.9032\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 803.5939 - accuracy: 0.8065\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1491.2510 - accuracy: 0.9032\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1089.0405 - accuracy: 0.8602\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 174.6138 - accuracy: 0.9032\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 537.7797 - accuracy: 0.8817\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 190.7837 - accuracy: 0.9355\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 69.8016 - accuracy: 0.9462\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 64.8169 - accuracy: 0.9247\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 583.6505 - accuracy: 0.9247\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 163.8499 - accuracy: 0.9355\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 29.3863 - accuracy: 0.9892\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1001.3837 - accuracy: 0.9247\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 215.7247 - accuracy: 0.9355\n",
      "training model 6d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 55ms/step - loss: 3625.0242 - accuracy: 0.5269\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 786.8629 - accuracy: 0.8495\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3810.4778 - accuracy: 0.5591\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3087.4946 - accuracy: 0.8495\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1119.7660 - accuracy: 0.8602\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3133.4502 - accuracy: 0.6022\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1524.0039 - accuracy: 0.8710\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1843.8430 - accuracy: 0.8172\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1331.7690 - accuracy: 0.8602\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 759.4902 - accuracy: 0.8817\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 526.3750 - accuracy: 0.9247\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 682.0639 - accuracy: 0.7849\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 530.5233 - accuracy: 0.9247\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 717.3828 - accuracy: 0.8602\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 233.4835 - accuracy: 0.8817\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 217.0683 - accuracy: 0.9355\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 109.8139 - accuracy: 0.8387\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 160.0332 - accuracy: 0.9140\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 64.0710 - accuracy: 0.8925\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 98.9342 - accuracy: 0.9355\n",
      "training model 7d\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 57ms/step - loss: 641.1517 - accuracy: 0.5484\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1041.7375 - accuracy: 0.8387\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 760.9307 - accuracy: 0.6774\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 411.8925 - accuracy: 0.8602\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1197.6893 - accuracy: 0.8172\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 994.0247 - accuracy: 0.7957\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1089.1544 - accuracy: 0.8495\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 383.2235 - accuracy: 0.8602\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 836.8996 - accuracy: 0.6559\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1710.0316 - accuracy: 0.8710\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1213.7136 - accuracy: 0.8817\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 833.2173 - accuracy: 0.6989\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 207.7300 - accuracy: 0.7527\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1339.6783 - accuracy: 0.8710\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 935.2581 - accuracy: 0.8925\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 543.4176 - accuracy: 0.8710\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 150.4353 - accuracy: 0.7097\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 111.0846 - accuracy: 0.8925\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 115.9930 - accuracy: 0.9247\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 129.2397 - accuracy: 0.8710\n"
     ]
    }
   ],
   "source": [
    "TRAINING_EPOCHS = 20\n",
    "\n",
    "# train all models\n",
    "for model, name in zip(models, modelNames):\n",
    "    print(f'training model {name}')\n",
    "    model.fit(X_train, y_train, epochs=TRAINING_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 7459.7197 - accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 848.6706 - accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3157.0688 - accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1041.7965 - accuracy: 0.9000\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x00000224DC610DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1185.0535 - accuracy: 0.6500\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000224D36DFEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 728.3759 - accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 0s/step - loss: 161.4709 - accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# get all model accuracy scores on test data\n",
    "scores = [model.evaluate(X_test,y_test)[1] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelNames.insert(0, 'perceptron')\n",
    "scores.insert(0, p.score(X_test, y_test) )\n",
    "\n",
    "plt.bar(modelNames,scores)\n",
    "plt.ylim(0.75, 1.0)\n",
    "plt.ylabel('Test Accuracy (%)') \n",
    "plt.xlabel(str(NODES_PER_HIDDEN_LAYER) + \" nodes per hidden layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000224DD830EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000224DD88E430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Model 1 Predicted Labels: [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 1 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 2 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 3 Predicted Labels: [0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0\n",
      " 0 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 4 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 5 Predicted Labels: [0 0 0 0 0 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 6 Predicted Labels: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Model 7 Predicted Labels: [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "Actual Labels: [0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "probabilities = [model.predict(X_test) for model in models]\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_labels = [np.argmax(prob, axis=1) for prob in probabilities]\n",
    "\n",
    "# Assuming y_test is your actual labels\n",
    "# Convert y_test to class labels if it's not already in that format\n",
    "# This step depends on how y_test is structured. If it's one-hot encoded, you might need to use np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print predicted and actual labels for each model\n",
    "for i, labels in enumerate(predicted_labels):\n",
    "    print(f\"Model {i+1} Predicted Labels: {labels}\")\n",
    "    print(f\"Actual Labels: {y_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
