{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow import keras\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_src_path = '../Dataset/assignment1New.json'\n",
    "y_src_path = '../DataBook/Assignment1_Data_Analyst.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(x_src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervision = pd.read_excel(y_src_path)\n",
    "plagiarised_array = df_supervision['Plagiarised'].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.nan_to_num(data.values, nan=0, copy=True).astype(int)\n",
    "y = plagiarised_array\n",
    "ros = SMOTE()\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=32)\n",
    "#seed 32 results 100% on test score 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 13\n",
      "Number of 1s: 4\n"
     ]
    }
   ],
   "source": [
    "count_0 = 0\n",
    "count_1 = 0\n",
    "\n",
    "for element in y_test:\n",
    "    if element == 0:\n",
    "        count_0 += 1\n",
    "    elif element == 1:\n",
    "        count_1 += 1\n",
    "\n",
    "print(\"Number of 0s:\", count_0)\n",
    "print(\"Number of 1s:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "#     print(\"this stage is \" + str(i))\n",
    "#     count_y_train_1 = np.sum(y_train == 1)\n",
    "#     count_y_test_1 = np.sum(y_test == 1)\n",
    "#     print(count_y_train_1)\n",
    "#     print(count_y_test_1)\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 1.0\n",
      "Test data score: 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "p = Perceptron()\n",
    "p.fit(X_train,y_train)\n",
    "\n",
    "print(f\"Training data score: {p.score(X_train, y_train)}\")\n",
    "print(f\"Test data score: {p.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        13\n",
      "           1       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.93      0.75      0.80        17\n",
      "weighted avg       0.90      0.88      0.87        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions = p.predict(X_test)\n",
    "# for i in range(len(X_test)):\n",
    "#     print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 1 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 1\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n",
      "Predicted: 0 Actual: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = p.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted:\", predictions[i], \"Actual:\", y_test[i])\n",
    "# y_pred = p.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNames = [\n",
    "    '1d',\n",
    "    '2d',\n",
    "    '3d',\n",
    "    '4d',\n",
    "    '5d',\n",
    "    '6d',\n",
    "    '7d'\n",
    "]\n",
    "\n",
    "NODES_PER_HIDDEN_LAYER = 64\n",
    "\n",
    "models = [ \n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(33813,)),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "    keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(33813,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(33813,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(33813,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    " keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(33813,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(33813,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "]),\n",
    "\n",
    "keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(33813,)),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(NODES_PER_HIDDEN_LAYER, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_FN = keras.losses.sparse_categorical_crossentropy\n",
    "\n",
    "for model in models:\n",
    "    model.compile(optimizer='adam',loss=LOSS_FN,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model 1d\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2598.1445 - accuracy: 0.4865\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2296.0261 - accuracy: 0.8378\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 875.1842 - accuracy: 0.8919\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 977.3984 - accuracy: 0.8919\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 760.0585 - accuracy: 0.9459\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 702.4393 - accuracy: 0.9189\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 553.0256 - accuracy: 0.9189\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 461.1285 - accuracy: 0.8919\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 221.1687 - accuracy: 0.8919\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 60.3428 - accuracy: 0.9730\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 163.1447 - accuracy: 0.9459\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 268.2788 - accuracy: 0.9459\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 408.8499 - accuracy: 0.8919\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 439.2727 - accuracy: 0.8919\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 295.7704 - accuracy: 0.9459\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 160.8548 - accuracy: 0.9459\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 72.0217 - accuracy: 0.9459\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.4019 - accuracy: 0.9730\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 64.2158 - accuracy: 0.9459\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 228.1514 - accuracy: 0.9189\n",
      "training model 2d\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1014.8801 - accuracy: 0.2432\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 9500.5547 - accuracy: 0.8378\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 9271.7207 - accuracy: 0.9189\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 7770.9233 - accuracy: 0.9189\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 5662.4805 - accuracy: 0.8919\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 3285.7053 - accuracy: 0.8919\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 883.3798 - accuracy: 0.9189\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 380.3822 - accuracy: 0.9189\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 108.3685 - accuracy: 0.9459\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 541.3267 - accuracy: 0.8919\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 95.1300 - accuracy: 0.9459\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 166.9733 - accuracy: 0.8919\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 102.8357 - accuracy: 0.9459\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 65.8805 - accuracy: 0.9459\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 19.3672 - accuracy: 0.9730\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 18.0314 - accuracy: 0.9730\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 16.7502 - accuracy: 0.9730\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 14.9733 - accuracy: 0.9730\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 26.4255 - accuracy: 0.9459\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 15.9332 - accuracy: 0.9459\n",
      "training model 3d\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 712.7772 - accuracy: 0.5135\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3355.2649 - accuracy: 0.8919\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1039.7018 - accuracy: 0.8649\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 112.6099 - accuracy: 0.9189\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 168.5452 - accuracy: 0.9459\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 294.3402 - accuracy: 0.9189\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 297.3915 - accuracy: 0.9189\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 199.7621 - accuracy: 0.9459\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 57.4767 - accuracy: 0.9459\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 4.6981 - accuracy: 0.9730\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 97.4560 - accuracy: 0.9459\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 28.8043 - accuracy: 0.9730\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 196.1383 - accuracy: 0.9459\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 494.8589 - accuracy: 0.9459\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1039.8293 - accuracy: 0.9730\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2668.3711 - accuracy: 0.9459\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 3235.9148 - accuracy: 0.9459\n",
      "training model 4d\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 88.1507 - accuracy: 0.6757\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1048.5363 - accuracy: 0.8108\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 658.4080 - accuracy: 0.8108\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1717.1049 - accuracy: 0.8919\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 416.4375 - accuracy: 0.8919\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 454.9725 - accuracy: 0.9189\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 497.0525 - accuracy: 0.9459\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 188.2680 - accuracy: 0.8919\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 172.9656 - accuracy: 0.9189\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 109.9360 - accuracy: 0.9189\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7612e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 138.9448 - accuracy: 0.9459\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 101.2304 - accuracy: 0.9459\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 50.6559 - accuracy: 0.9730\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 11.9397 - accuracy: 0.9730\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.7216e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 25.2227 - accuracy: 0.9730\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 9.0892 - accuracy: 0.9730\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.3504 - accuracy: 0.9730\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.7914e-04 - accuracy: 1.0000\n",
      "training model 5d\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 360.6941 - accuracy: 0.5946\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 385.7098 - accuracy: 0.8378\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 496.7734 - accuracy: 0.7568\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 96.1659 - accuracy: 0.8919\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 245.0206 - accuracy: 0.8108\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 61.8824 - accuracy: 0.8919\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5399 - accuracy: 0.9730\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 97.8623 - accuracy: 0.9730\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 118.6586 - accuracy: 0.9459\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 51.5225 - accuracy: 0.9459\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 9.8913 - accuracy: 0.9459\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 182.0141 - accuracy: 0.8108\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 11.6867 - accuracy: 0.9730\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 37.6401 - accuracy: 0.9459\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 45.2866 - accuracy: 0.9459\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 40.5997 - accuracy: 0.9459\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 27.3315 - accuracy: 0.9730\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 17.3684 - accuracy: 0.9459\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 13.8946 - accuracy: 0.9459\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 11.2668 - accuracy: 0.9730\n",
      "training model 6d\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 1178.2747 - accuracy: 0.1892\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 538.2033 - accuracy: 0.8649\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 337.8800 - accuracy: 0.9189\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 370.1374 - accuracy: 0.8919\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 400.1985 - accuracy: 0.8649\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 24.3660 - accuracy: 0.9459\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 384.1789 - accuracy: 0.8378\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 236.5709 - accuracy: 0.9189\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 25.4388 - accuracy: 0.9459\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 24.3555 - accuracy: 0.9730\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 18.9846 - accuracy: 0.9730\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 6.1383 - accuracy: 0.9730\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 197.5434 - accuracy: 0.9189\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 7.3654 - accuracy: 0.9730\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7710 - accuracy: 0.9730\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 415.0468 - accuracy: 0.9459\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 261.0281 - accuracy: 0.9730\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6333 - accuracy: 0.9730\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.8777 - accuracy: 0.9730\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5391 - accuracy: 0.9730\n",
      "training model 7d\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 106.2774 - accuracy: 0.3243\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 631.4320 - accuracy: 0.5135\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 319.3487 - accuracy: 0.8108\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 253.2261 - accuracy: 0.7838\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 164.8591 - accuracy: 0.8378\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 249.6679 - accuracy: 0.8649\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 94.8526 - accuracy: 0.9189\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 162.3769 - accuracy: 0.8108\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 35.8689 - accuracy: 0.9459\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 576.5931 - accuracy: 0.7838\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 218.1528 - accuracy: 0.8919\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 84.4095 - accuracy: 0.9189\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 257.9978 - accuracy: 0.9189\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 301.0686 - accuracy: 0.9189\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 253.3301 - accuracy: 0.9459\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 117.9376 - accuracy: 0.9459\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.3000 - accuracy: 0.9730\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.4846 - accuracy: 0.9730\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.4586 - accuracy: 0.9730\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 3.7708 - accuracy: 0.9459\n"
     ]
    }
   ],
   "source": [
    "TRAINING_EPOCHS = 20\n",
    "\n",
    "# train all models\n",
    "for model, name in zip(models, modelNames):\n",
    "    print(f'training model {name}')\n",
    "    model.fit(X_train, y_train, epochs=TRAINING_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step - loss: 6032.6582 - accuracy: 0.8235\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 6851.9648 - accuracy: 0.8235\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 13444.9834 - accuracy: 0.7647\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1737.9944 - accuracy: 0.8824\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 584.6304 - accuracy: 0.7647\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 304.0724 - accuracy: 0.8235\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 119.3755 - accuracy: 0.8235\n"
     ]
    }
   ],
   "source": [
    "# get all model accuracy scores on test data\n",
    "scores = [model.evaluate(X_test,y_test)[1] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelNames.insert(0, 'perceptron')\n",
    "scores.insert(0, p.score(X_test, y_test) )\n",
    "\n",
    "plt.bar(modelNames,scores)\n",
    "plt.ylim(0.75, 1.0)\n",
    "plt.ylabel('Test Accuracy (%)') \n",
    "plt.xlabel(str(NODES_PER_HIDDEN_LAYER) + \" nodes per hidden layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90        13\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.91      0.62      0.65        17\n",
      "weighted avg       0.86      0.82      0.78        17\n",
      "\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89        13\n",
      "           1       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.76      0.71      0.73        17\n",
      "weighted avg       0.81      0.82      0.81        17\n",
      "\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86        13\n",
      "           1       0.50      0.25      0.33         4\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.65      0.59      0.60        17\n",
      "weighted avg       0.73      0.76      0.73        17\n",
      "\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        13\n",
      "           1       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.93      0.75      0.80        17\n",
      "weighted avg       0.90      0.88      0.87        17\n",
      "\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        13\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.67      0.67      0.67        17\n",
      "weighted avg       0.76      0.76      0.76        17\n",
      "\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88        13\n",
      "           1       0.60      0.75      0.67         4\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.76      0.80      0.77        17\n",
      "weighted avg       0.84      0.82      0.83        17\n",
      "\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90        13\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.91      0.62      0.65        17\n",
      "weighted avg       0.86      0.82      0.78        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming `models` is a list of models\n",
    "for idx, model in enumerate(models):\n",
    "    # Make predictions for the current model\n",
    "    y_pred_model = model.predict(X_test)\n",
    "    y_pred_class = np.argmax(y_pred_model, axis=1)\n",
    "    print(classification_report(y_test, y_pred_class))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
